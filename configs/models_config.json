
{
  "ollama_models": {
    "llama2:7b": {
      "name": "Llama 2 7B",
      "size": "3.8GB",
      "capabilities": ["conversation", "reasoning", "code"],
      "recommended": true
    },
    "mistral:7b": {
      "name": "Mistral 7B",
      "size": "4.1GB",
      "capabilities": ["conversation", "reasoning", "multilingual"],
      "recommended": true
    },
    "codellama:7b": {
      "name": "Code Llama 7B",
      "size": "3.8GB",
      "capabilities": ["code", "programming", "debugging"],
      "recommended": false
    }
  },
  "vosk_models": {
    "vosk-model-en-us-0.22": {
      "language": "en-US",
      "size": "1.8GB",
      "accuracy": "high",
      "url": "https://alphacephei.com/vosk/models/vosk-model-en-us-0.22.zip"
    },
    "vosk-model-small-en-us-0.15": {
      "language": "en-US",
      "size": "40MB",
      "accuracy": "medium",
      "url": "https://alphacephei.com/vosk/models/vosk-model-small-en-us-0.15.zip"
    }
  },
  "spacy_models": {
    "en_core_web_sm": {
      "language": "English",
      "size": "15MB",
      "features": ["tokenization", "pos", "ner", "parsing"]
    }
  }
}
